[
  {
    "path": "posts/WWI_viewer/",
    "title": " WWI VieweR, A shiny app to visualize the battles of the first world war",
    "description": "WWI VieweR, A shiny app to visualize the battles of the first world war.",
    "author": [
      {
        "name": "Etienne Rolland",
        "url": "https://github.com/Cdk29"
      }
    ],
    "date": "2023-01-24",
    "categories": [],
    "contents": "\nwwi_viewerWWI VieweR\nHi everyone ! Long time no see. I recently undertook to validate the capstone project of the Data Visualization specialization of the Johns Hopkins University on Coursera, with something that was probably a slight overkill for the requirements. Beeing without any idea around the 10th November, I came up with the idea of visualizing the battles of the first world war the 11th.\nThe app is hosted here : https://cdk296.shinyapps.io/WWI_VieweR/ and the code of the application and of the scrapping is accessible on this github repo. The structure of the repo is somewhat messy because of the structuring of the course in different weeks.\nI ended up carrying this project quite longer than I expected (cf the date of this blog post). I also learnt some things that I did not expected to learn, such as how to query Dbpedia using SPARQL with the help of ten years old R-bloggers posts. I discovered some battles and fronts. Also, even if you know that the war had a huge impacts on the societies of the time, plotting the percentage of death per population certainly help to grasp what this could have means for the contemporaries.\nI also discovered that, when you are French and start by plotting the battles of the western front, the current map of the world provided by leaflet works very well, since boundaries did not changed since one century. When you start plotting the battles of other fronts, such as the middle east, it became quickly out-of-context. I remember that T.E. Lawrence mentioned Mesopotamia and probably Persia in his books, countries you will have trouble to find now on a map.\nData:\nI originally started with the CDB90 dataset, planning to recover the latitude and longitude for each battle from Dbpedia. But the URLs links inside the battles.csv where somewhat too old, and query using them were not working.\nI ended up querying directly dbpedia, using the code in the file Week_2.Rmd and scrapping_all_ww1.Rmd (the file is named Week_2 because of the segmentation of the capstone project course on Coursera)/\nSee the github repo.\nSome Data limitation\nFacts in history are not that objective or simple. For exemple, is a battle a victory or not ? Take for example the Battle of Jutland, both camps claimed victory, because they were pursuing differents objectives.\nAlso, some results of battle may vary depending the language used for scrapping (for the second world war I remember that the protagonist of the liberation of Rome is somewhat different based on the langage consulted ;p).\nRegarding the scrapping, I am pretty sure some battles are missings, for exemple in the eastern front of the war. Not sure why.\nAlso, the map where I mapped the battles is a contemporary map. Too bad there is not a world map of 1914 accessible on Leafleat.\n\n\n\n",
    "preview": {},
    "last_modified": "2023-01-24T11:56:07+01:00",
    "input_file": "WWI_viewer.knit.md"
  },
  {
    "path": "posts/Cyclical_lr_post/",
    "title": "Cyclical learning rate with R and Keras",
    "description": "An example on how to perform cyclical learning rate with EfficientNet in R and \nKeras.",
    "author": [
      {
        "name": "Etienne Rolland",
        "url": "https://github.com/Cdk29"
      }
    ],
    "date": "2021-06-30",
    "categories": [],
    "contents": "\nEfficientnet with R and Tf2\nIn this blog post I will share a way to perform cyclical learning rate, with R. I worked on top of some source code I found on a other blog, by chance, but I adjusted things to make it more similar to the fast.ai approach. Also, my blog is on R-bloggers, so other R users that might want to use cyclical learning rate with R will have less trouble to find it. Sometimes things are possible in R, but, since our community is smaller, we don’t have that many resources or tutorials compared to the python community.\nWhat is cyclical learning rate ? In a nutshell it is mostly about varying the learning rate around a min and max value during an epoch. The interests are that : 1) you don’t need to keep trying different learning rate, 2) it works as a form of regularization. Also, it trains the network faster (a phenomenon named “super convergence”).\nAbout the data\nI wrote this code in the first place in the context of the Cassava Leaf Disease Classification, a Kaggle’s competition where the goal was to train a model to identify the disease on leafs of cassava. Like the last time the I will use an Efficientnet0.\n\n\n#reticulate::py_install(packages = \"tensorflow\", version = \"2.3.0\", pip=TRUE)\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(tensorflow)\ntf$executing_eagerly()\n\n\n[1] TRUE\n\n\n\ntensorflow::tf_version()\n\n\n[1] '2.3'\n\nHere I flex with my own version of keras. Basically, it is a fork with application wrapper for the efficient net.\nDisclaimer : I did not write the code for the really handy applications wrappers. It came from this commit for which the PR is hold until the fully release of tf 2.3, as stated in this PR. I am not sure why the PR is closed.\n\n\ndevtools::install_github(\"Cdk29/keras\", dependencies = FALSE)\n\n\n\n\n\nlibrary(keras)\n\n\n\n\n\nlabels<-read_csv('train.csv')\nhead(labels)\n\n\n# A tibble: 6 x 2\n  image_id       label\n  <chr>          <dbl>\n1 1000015157.jpg     0\n2 1000201771.jpg     3\n3 100042118.jpg      1\n4 1000723321.jpg     1\n5 1000812911.jpg     3\n6 1000837476.jpg     3\n\n\n\nlevels(as.factor(labels$label))\n\n\n[1] \"0\" \"1\" \"2\" \"3\" \"4\"\n\n\n\nidx0<-which(labels$label==0)\nidx1<-which(labels$label==1)\nidx2<-which(labels$label==2)\nidx3<-which(labels$label==3)\nidx4<-which(labels$label==4)\n\n\n\n\n\nlabels$CBB<-0\nlabels$CBSD<-0\nlabels$CGM<-0\nlabels$CMD<-0\nlabels$Healthy<-0\n\n\n\n\n\nlabels$CBB[idx0]<-1\nlabels$CBSD[idx1]<-1\nlabels$CGM[idx2]<-1\nlabels$CMD[idx3]<-1\n\n\n\n“Would it have been easier to create a function to convert the labelling ?” You may ask.\n\n\nlabels$Healthy[idx4]<-1\n\n\n\nProbably.\n\n\n#labels$label<-NULL\n\n\n\n\n\nhead(labels)\n\n\n# A tibble: 6 x 7\n  image_id       label   CBB  CBSD   CGM   CMD Healthy\n  <chr>          <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>\n1 1000015157.jpg     0     1     0     0     0       0\n2 1000201771.jpg     3     0     0     0     1       0\n3 100042118.jpg      1     0     1     0     0       0\n4 1000723321.jpg     1     0     1     0     0       0\n5 1000812911.jpg     3     0     0     0     1       0\n6 1000837476.jpg     3     0     0     0     1       0\n\nFollowing code is retaken from this online notebook named simple-convnet, which used a better approach to create a validation set than I did in the first place (not at random, but with stratification) :\n\n\nset.seed(6)\n\ntmp = splitstackshape::stratified(labels, c('label'), 0.90, bothSets = TRUE)\n\ntrain_labels = tmp[[1]]\nval_labels = tmp[[2]]\n\n#following line for knowledge distillation : \nwrite.csv(val_labels, file='validation_set.csv', row.names=FALSE, quote=FALSE)\n\n\ntrain_labels$label<-NULL\nval_labels$label<-NULL\n\nhead(train_labels)\n\n\n         image_id CBB CBSD CGM CMD Healthy\n1: 3903787097.jpg   1    0   0   0       0\n2: 1026467332.jpg   1    0   0   0       0\n3:  436868168.jpg   1    0   0   0       0\n4: 2270851426.jpg   1    0   0   0       0\n5: 3234915269.jpg   1    0   0   0       0\n6: 3950368220.jpg   1    0   0   0       0\n\nhead(val_labels)\n\n\n         image_id CBB CBSD CGM CMD Healthy\n1: 1003442061.jpg   0    0   0   0       1\n2: 1004672608.jpg   0    0   0   1       0\n3: 1007891044.jpg   0    0   0   1       0\n4: 1009845426.jpg   0    0   0   1       0\n5: 1010648150.jpg   0    0   0   1       0\n6: 1011139244.jpg   0    0   0   1       0\n\n\n\nsummary(train_labels)\n\n\n   image_id              CBB               CBSD       \n Length:19256       Min.   :0.00000   Min.   :0.0000  \n Class :character   1st Qu.:0.00000   1st Qu.:0.0000  \n Mode  :character   Median :0.00000   Median :0.0000  \n                    Mean   :0.05079   Mean   :0.1023  \n                    3rd Qu.:0.00000   3rd Qu.:0.0000  \n                    Max.   :1.00000   Max.   :1.0000  \n      CGM              CMD           Healthy      \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000  \n Median :0.0000   Median :1.000   Median :0.0000  \n Mean   :0.1115   Mean   :0.615   Mean   :0.1204  \n 3rd Qu.:0.0000   3rd Qu.:1.000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000  \n\n\n\nsummary(val_labels)\n\n\n   image_id              CBB               CBSD       \n Length:2141        Min.   :0.00000   Min.   :0.0000  \n Class :character   1st Qu.:0.00000   1st Qu.:0.0000  \n Mode  :character   Median :0.00000   Median :0.0000  \n                    Mean   :0.05091   Mean   :0.1023  \n                    3rd Qu.:0.00000   3rd Qu.:0.0000  \n                    Max.   :1.00000   Max.   :1.0000  \n      CGM              CMD            Healthy      \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :1.0000   Median :0.0000  \n Mean   :0.1116   Mean   :0.6147   Mean   :0.1205  \n 3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\nimage_path<-'cassava-leaf-disease-classification/train_images/'\n\n\n\n\n\n#data augmentation\ndatagen <- image_data_generator(\n  rotation_range = 40,\n  width_shift_range = 0.2,\n  height_shift_range = 0.2,\n  shear_range = 0.2,\n  zoom_range = 0.5,\n  horizontal_flip = TRUE,\n  fill_mode = \"reflect\"\n)\n\n\n\n\n\nimg_path<-\"cassava-leaf-disease-classification/train_images/1000015157.jpg\"\n\nimg <- image_load(img_path, target_size = c(448, 448))\nimg_array <- image_to_array(img)\nimg_array <- array_reshape(img_array, c(1, 448, 448, 3))\nimg_array<-img_array/255\n# Generated that will flow augmented images\naugmentation_generator <- flow_images_from_data(\n  img_array, \n  generator = datagen, \n  batch_size = 1 \n)\nop <- par(mfrow = c(2, 2), pty = \"s\", mar = c(1, 0, 1, 0))\nfor (i in 1:4) {\n  batch <- generator_next(augmentation_generator)\n  plot(as.raster(batch[1,,,]))\n}\n\n\n\npar(op)\n\n\n\nMaybe you can skip the conversion of the label into 1 and 0 and directly create train generator from the original label column of the dataframe.\n\n\ntrain_generator <- flow_images_from_dataframe(dataframe = train_labels, \n                                              directory = image_path,\n                                              generator = datagen,\n                                              class_mode = \"other\",\n                                              x_col = \"image_id\",\n                                              y_col = c(\"CBB\",\"CBSD\", \"CGM\", \"CMD\", \"Healthy\"),\n                                              target_size = c(448, 448),\n                                              batch_size=16)\n\nvalidation_generator <- flow_images_from_dataframe(dataframe = val_labels, \n                                              directory = image_path,\n                                              class_mode = \"other\",\n                                              x_col = \"image_id\",\n                                              y_col = c(\"CBB\",\"CBSD\", \"CGM\", \"CMD\", \"Healthy\"),\n                                              target_size = c(448, 448),\n                                              batch_size=16)\n\n\n\nAbout tf hub\nI tried a lot of things with tf hub before using the application wrappers. The application wrappers is handy, tf hub is not (for this task.) That will be the subject of an other blog post I think.\n\n\nconv_base<-keras::application_efficientnet_b0(weights = \"imagenet\", include_top = FALSE, input_shape = c(448, 448, 3))\n\nfreeze_weights(conv_base)\n\nmodel <- keras_model_sequential() %>%\n    conv_base %>% \n    layer_global_max_pooling_2d() %>% \n    layer_batch_normalization() %>% \n    layer_dropout(rate=0.5) %>%\n    layer_dense(units=5, activation=\"softmax\")\n\nsummary(model)\n\n\nModel: \"sequential\"\n______________________________________________________________________\nLayer (type)                   Output Shape                Param #    \n======================================================================\nefficientnetb0 (Functional)    (None, 14, 14, 1280)        4049571    \n______________________________________________________________________\nglobal_max_pooling2d (GlobalMa (None, 1280)                0          \n______________________________________________________________________\nbatch_normalization (BatchNorm (None, 1280)                5120       \n______________________________________________________________________\ndropout (Dropout)              (None, 1280)                0          \n______________________________________________________________________\ndense (Dense)                  (None, 5)                   6405       \n======================================================================\nTotal params: 4,061,096\nTrainable params: 8,965\nNon-trainable params: 4,052,131\n______________________________________________________________________\n\nCyclical learning rate\nA lot of the code below came from the blog “the cool data”. The idea to have a tail and the notion of annihilation of gradient originate from this blog post on The 1cycle policy and is quite similar to the one used in fastai. The big difference is that I do not want to add an other vector of an even lower learning rate at the end of the one generated by the function Cyclic_lr, it would force me to take it into account and create an other number of iteration for the compilation of the model. I prefer the approach of dividing more and more the last element of the cycle.\n\n\ncallback_lr_init <- function(logs){\n      iter <<- 0\n      lr_hist <<- c()\n      iter_hist <<- c()\n}\ncallback_lr_set <- function(batch, logs){\n      iter <<- iter + 1\n      LR <- l_rate[iter] # if number of iterations > l_rate values, make LR constant to last value\n      if(is.na(LR)) LR <- l_rate[length(l_rate)]\n      k_set_value(model$optimizer$lr, LR)\n}\n\ncallback_lr <- callback_lambda(on_train_begin=callback_lr_init, on_batch_begin=callback_lr_set)\n\n\n\n\n\n####################\nCyclic_LR <- function(iteration=1:32000, base_lr=1e-5, max_lr=1e-3, step_size=2000, mode='triangular', gamma=1, scale_fn=NULL, scale_mode='cycle'){ # translated from python to R, original at: https://github.com/bckenstler/CLR/blob/master/clr_callback.py # This callback implements a cyclical learning rate policy (CLR). # The method cycles the learning rate between two boundaries with # some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186). # The amplitude of the cycle can be scaled on a per-iteration or per-cycle basis. # This class has three built-in policies, as put forth in the paper. # - \"triangular\": A basic triangular cycle w/ no amplitude scaling. # - \"triangular2\": A basic triangular cycle that scales initial amplitude by half each cycle. # - \"exp_range\": A cycle that scales initial amplitude by gamma**(cycle iterations) at each cycle iteration. # - \"sinus\": A sinusoidal form cycle # # Example # > clr <- Cyclic_LR(base_lr=0.001, max_lr=0.006, step_size=2000, mode='triangular', num_iterations=20000) # > plot(clr, cex=0.2)\n \n      # Class also supports custom scaling functions with function output max value of 1:\n      # > clr_fn <- function(x) 1/x # > clr <- Cyclic_LR(base_lr=0.001, max_lr=0.006, step_size=400, # scale_fn=clr_fn, scale_mode='cycle', num_iterations=20000) # > plot(clr, cex=0.2)\n \n      # # Arguments\n      #   iteration:\n      #       if is a number:\n      #           id of the iteration where: max iteration = epochs * (samples/batch)\n      #       if \"iteration\" is a vector i.e.: iteration=1:10000:\n      #           returns the whole sequence of lr as a vector\n      #   base_lr: initial learning rate which is the\n      #       lower boundary in the cycle.\n      #   max_lr: upper boundary in the cycle. Functionally,\n      #       it defines the cycle amplitude (max_lr - base_lr).\n      #       The lr at any cycle is the sum of base_lr\n      #       and some scaling of the amplitude; therefore \n      #       max_lr may not actually be reached depending on\n      #       scaling function.\n      #   step_size: number of training iterations per\n      #       half cycle. Authors suggest setting step_size\n      #       2-8 x training iterations in epoch.\n      #   mode: one of {triangular, triangular2, exp_range, sinus}.\n      #       Default 'triangular'.\n      #       Values correspond to policies detailed above.\n      #       If scale_fn is not None, this argument is ignored.\n      #   gamma: constant in 'exp_range' scaling function:\n      #       gamma**(cycle iterations)\n      #   scale_fn: Custom scaling policy defined by a single\n      #       argument lambda function, where \n      #       0 <= scale_fn(x) <= 1 for all x >= 0.\n      #       mode paramater is ignored \n      #   scale_mode: {'cycle', 'iterations'}.\n      #       Defines whether scale_fn is evaluated on \n      #       cycle number or cycle iterations (training\n      #       iterations since start of cycle). Default is 'cycle'.\n \n      ########\n      if(is.null(scale_fn)==TRUE){\n            if(mode=='triangular'){scale_fn <- function(x) 1; scale_mode <- 'cycle';}\n            if(mode=='triangular2'){scale_fn <- function(x) 1/(2^(x-1)); scale_mode <- 'cycle';}\n            if(mode=='exp_range'){scale_fn <- function(x) gamma^(x); scale_mode <- 'iterations';}\n            if(mode=='sinus'){scale_fn <- function(x) 0.5*(1+sin(x*pi/2)); scale_mode <- 'cycle';}\n            if(mode=='halfcosine'){scale_fn <- function(x) 0.5*(1+cos(x*pi)^2); scale_mode <- 'cycle';}\n      }\n      lr <- list()\n      if(is.vector(iteration)==TRUE){\n            for(iter in iteration){\n                  cycle <- floor(1 + (iter / (2*step_size)))\n                  x2 <- abs(iter/step_size-2 * cycle+1)\n                  if(scale_mode=='cycle') x <- cycle\n                  if(scale_mode=='iterations') x <- iter\n                  lr[[iter]] <- base_lr + (max_lr-base_lr) * max(0,(1-x2)) * scale_fn(x)\n            }\n      }\n      lr <- do.call(\"rbind\",lr)\n      return(as.vector(lr))\n}\n\n\n\nThe tail\nOkay, what is going on here ? Simple speaking I want the last steps to go several order of magnitude under the minimal learning rate, in a similar fashion of the fast.ai implementation. The most elegant way (without adding an other vector at the end) to do this is to divide the learning rate of the last steps by a number growing exponentially (to avoid a cut in the learning rate curve by dividing the number suddenly by 10). So we have a nice “tail” (see graphs below).\nOh there is no specific justifications for the exponent number. Just trial and error and “looking nice” approach.\n\n\nn=200\nnb_epochs=10\n\n\n\n\n\ntail <- 30 #annhilation of the gradient\ni<-1:tail\nl_rate_div<-1.1*(1.2^i) \nplot(l_rate_div, type=\"b\", pch=16, cex=0.1, xlab=\"iteration\", ylab=\"learning rate dividor\")\n\n\n\n\n\n\nl_rate_cyclical <- Cyclic_LR(iteration=1:n, base_lr=1e-7, max_lr=1e-3, step_size=floor(n/2),\n                        mode='triangular', gamma=1, scale_fn=NULL, scale_mode='cycle')\n\nstart_tail <-length(l_rate_cyclical)-tail\nend_tail <- length(l_rate_cyclical)\nl_rate_cyclical[start_tail:end_tail] <- l_rate_cyclical[start_tail:end_tail]/l_rate_div\n\n\n\n\n\nl_rate <- rep(l_rate_cyclical, nb_epochs)\n\nplot(l_rate_cyclical, type=\"b\", pch=16, xlab=\"iteration\", cex=0.2, ylab=\"learning rate\", col=\"grey50\")\n\n\n\nplot(l_rate, type=\"b\", pch=16, xlab=\"iteration\", cex=0.2, ylab=\"learning rate\", col=\"grey50\")\n\n\n\n\n\n\nmodel %>% compile(\n    optimizer=optimizer_rmsprop(lr=1e-5),\n    loss=\"categorical_crossentropy\",\n    metrics = \"categorical_accuracy\"\n)\n\n\n\nYou can still add other callback, the following code came from the tutorial of Keras “tutorial_save_and_restore”. Commented to lighten the blog post.\n\n\n# checkpoint_dir <- \"checkpoints\"\n# unlink(checkpoint_dir, recursive = TRUE)\n# dir.create(checkpoint_dir)\n# filepath <- file.path(checkpoint_dir, \"eff_net_weights.{epoch:02d}.hdf5\")\n\n\n\n\n\n# check_point_callback <- callback_model_checkpoint(\n#   filepath = filepath,\n#   save_weights_only = TRUE,\n#   save_best_only = TRUE\n# )\n\n\n\n\n\n#callback_list<-list(callback_lr, check_point_callback ) #callback to update lr\ncallback_list<-list(callback_lr)\n\n\n\n\n\nhistory <- model %>% fit_generator(\n    train_generator,\n    steps_per_epoch=n,\n    epochs = nb_epochs,\n    callbacks = callback_list, #callback to update cylic lr\n    validation_data = validation_generator,\n    validation_step=40\n)\n\n\n\n\n\nplot(history)\n\n\n\n\nFine tuning\nHere the steps, are, basically the same, you you want to divide the maximum learning rate by 5 or 10, since you unfreeze the basal part of the network.\n\n\nunfreeze_weights(conv_base, from = 'block5a_expand_conv')\n\n\n\n\n\nsummary(model)\n\n\nModel: \"sequential\"\n______________________________________________________________________\nLayer (type)                   Output Shape                Param #    \n======================================================================\nefficientnetb0 (Functional)    (None, 14, 14, 1280)        4049571    \n______________________________________________________________________\nglobal_max_pooling2d (GlobalMa (None, 1280)                0          \n______________________________________________________________________\nbatch_normalization (BatchNorm (None, 1280)                5120       \n______________________________________________________________________\ndropout (Dropout)              (None, 1280)                0          \n______________________________________________________________________\ndense (Dense)                  (None, 5)                   6405       \n======================================================================\nTotal params: 4,061,096\nTrainable params: 3,707,853\nNon-trainable params: 353,243\n______________________________________________________________________\n\n\n\nnb_epochs<-20\n\n\n\n\n\nl_rate_cyclical <- Cyclic_LR(iteration=1:n, base_lr=1e-7, max_lr=(1e-3/5), step_size=floor(n/2),\n                        mode='triangular', gamma=1, scale_fn=NULL, scale_mode='cycle')\n\n\n\n\n\nstart_tail <-length(l_rate_cyclical)-tail\nend_tail <- length(l_rate_cyclical)\nl_rate_cyclical[start_tail:end_tail] <- l_rate_cyclical[start_tail:end_tail]/l_rate_div\n\nl_rate <- rep(l_rate_cyclical, nb_epochs)\n\n#plot(l_rate, type=\"b\", pch=16, xlab=\"iteration\", cex=0.2, ylab=\"learning rate\", col=\"grey50\")\n\n\n\n\n\nmodel %>% compile(\n    optimizer=optimizer_rmsprop(lr=1e-5),\n    loss=\"categorical_crossentropy\",\n    metrics = \"categorical_accuracy\"\n)\n\n\n\n\n\ncallback_list<-list(callback_lr)\n\n\n\n\n\nhistory <- model %>% fit_generator(\n    train_generator,\n    steps_per_epoch=n,\n    epochs = nb_epochs,\n    callbacks = callback_list, #callback to update cylic lr\n    validation_data = validation_generator,\n    validation_step=40\n)\n\n\n\n\n\nplot(history)\n\n\n\n\nConclusion\nAnd this is how you (can) do cyclical learning rate with R.\nLooking at this blog post, I realize that I don’t go really deep into the details on how I construct the network or how I choose learning rate parameters. It is more a general deep learning background knowledge, and habits took from fastai, but I can go back to this notions in others blog posts. Usually, you can cycle around 10 ^-3 for this type of task to train the head of the network, but the beauty of cyclical learning rate is that you can test quickly differents intervals (since it converges faster) without worrying too much about it, since you will probably oscillate around the good(s) solution(s). You can also ask questions in the comments sections.\nRemember, I am not an expert. I use books and complains when there is not the beginning of a tutorial for what I want to do. Reason why I wrote this blog.\n\n\n\n",
    "preview": "posts/Cyclical_lr_post/distill-preview.png",
    "last_modified": "2021-06-30T10:34:19+02:00",
    "input_file": "efficientnetb0-with-r-and-tf2-cyclic-lr.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/segmenteR_post/",
    "title": "segmenteR, a small tool to segment a scientific article",
    "description": "segmenteR is a prototype package to segment scientific articles into their \ndifferent sections, such as material and methods.",
    "author": [
      {
        "name": "Etienne Rolland",
        "url": "https://github.com/Cdk29"
      }
    ],
    "date": "2021-06-11",
    "categories": [],
    "contents": "\nsegmenteR\nHi everyone ! Whether it is to perform systematic review, some data extraction, or a really specific project that requires it, you may need to extract a particular section from an scientific article in pdf format. If that is the case, you may be curious in this (prototype) R package, segmenteR, a tool to extract a section, for example, “material and methods”, from the pdf of an article, using the fonts information from the pdf and natural language processing.\nContext\nIt has been elaborated in the context of a research work conducted at the Joint Research Centre, Directorate F - Health, Consumers and Reference Materials, Ispra (VA), as a sub-part of a project that aimed to analyse a corpus of 801 articles, obtained from the PubMed MeSH database and related to several toxicity topics (cardiotoxicity, genotoxicity, etc).\nWe needed to extract both the material and methods section and the results section of each articles, to evaluate the quality of the reporting inside each articles and parse the texts for specific toxicity effects. The work has been published in the Journal of Applied Toxicology, Toxicity effects of nanomaterials for health applications: how automation can support systematic review of the literature ? Blanka Halamoda-Kenzaoui, Etienne Rolland, Jacopo Piovesan, Antonio Puertas Gallardo, Susanne Bremer-Hoffmann doi.org/10.1002/jat.4204.\nWhile this tool is a prototype, it has a small benchmark to evaluate its performances, as shown inside the article.\nRequirement\nTo extract the informations on the fonts inside the pdf we use Poppler, the PDF rendering library and its cpp API. SegmenteR require a version of poppler >= 0.89 as well as a recent version of pdftools. The dev version of pdftools integrate the required change, but you need to install it from github :\n\n\ndevtools::install_github(\"ropensci/pdftools\") \ndevtools::install_github(\"ec-jrc/jrc_f2_refine\", subdir=\"segmenteR\") \n\n\n\nGetting started\nThe short way\nDownload an open access article that was part of the corpus :\n\n\nurl <- ('https://www.cell.com/action/showPdf?pii=S1525-0016%2816%2931594-5')\ndownload.file(url, 'Abrams, M T et al 2010.pdf')\n\n\n\nWe need a model and from the library udpipe to tokenize and annotate the text :\n\n\n## got the model for annotation\ndl <- udpipe::udpipe_download_model(\"english-gum\")\nstr(dl)\n\n\n'data.frame':   1 obs. of  5 variables:\n $ language        : chr \"english-gum\"\n $ file_model      : chr \"/home/erolland/Bureau/casualR/_posts/segmenteR_post/english-gum-ud-2.5-191206.udpipe\"\n $ url             : chr \"https://raw.githubusercontent.com/jwijffels/udpipe.models.ud.2.5/master/inst/udpipe-ud-2.5-191206/english-gum-u\"| __truncated__\n $ download_failed : logi FALSE\n $ download_message: chr \"OK\"\n\n\n\nmodel <- udpipe::udpipe_load_model(file = dl$file_model)\n#model\n\n\n\n\n\nlibrary(segmenteR)\n## basic example code\n\nsection_aliases <- c(\"material\", \"method\", \"experimental\", \"experiment\", \"methodology\")\n\n#model definition can be skipped, the function can download it automatically\nmaterial_and_methods <- segmenteR::extract_section_from_pdf(pdf_name=\"Abrams, M T et al 2010.pdf\",\n                                                             udpipe_model=model, \n                                                             section_aliases=section_aliases)\n\nhead(unique(material_and_methods$sentence))\n\n\n[1] \"MAterIAls And Methods Animals.\"                                                                                                                                                                           \n[2] \"Female Crl:CD-1/ICR mice were obtained from Charles River (Wilmington, MA) and were between 6 and 10 weeks old at time of study (25–30 g).\"                                                               \n[3] \"All studies were performed in Merck Research Laboratories′\"                                                                                                                                               \n[4] \"AAALAC-accredited West Point, PA animal facility using protocols approved by the Institutional Animal Care and Use Committee.\"                                                                            \n[5] \"Liposome assemblies, siRNAs, and reagents.\"                                                                                                                                                               \n[6] \"siRNA Lipid Nanoparticles were assembled using a process involving simultaneous mixing of the lipid mixture in an ethanol solution with an aqueous solution of siRNA, followed by stepwise diafiltration.\"\n\nAnd shazam, you have (hopefully) your material and methods section in ConLL-U format inside the dataframe material_and_methods, a format suitable for parsing, etc. You can stop reading this blog entry here.\nA more in-depth example\nThis example show the inner working of the function extract_section_from_pdf(), and some functions you made need :\n\n\npdf_name <- \"Abrams, M T et al 2010.pdf\"\nremove_bibliography <- TRUE\n\ntxt_pdf <- tabulizer::extract_text(pdf_name) # read the text from the pdf\ntxt_pdf <- segmenteR::preprocess_article_txt(txt_pdf)\n\n\n\nThe role of the function annotate_txt_pdf() is to load the required model and use the library udpipe to tokenize and annotate the text. Please refer to the vignette or the excellent website of udpipe to get more details on the Conll-U format. The reason for this annotation is that we will need it to estimate where the section titles are the most likely placed. For example, if it is the first word of a sentence, if the the word of the sentence is also a section title, etc, it is probably a section title.\n\n\nconllu_df <- segmenteR::annotate_txt_pdf(txt_pdf, udpipe_model=model ) # create the dataframe for NLP using udpipe\nhead(conllu_df)\n\n\n  doc_id paragraph_id sentence_id\n1   doc1            1           1\n2   doc1            1           1\n3   doc1            1           1\n4   doc1            1           1\n5   doc1            1           1\n6   doc1            1           1\n                                                                              sentence\n1 original article© The American Society of Gene & Cell Therapy Molecular Therapy vol.\n2 original article© The American Society of Gene & Cell Therapy Molecular Therapy vol.\n3 original article© The American Society of Gene & Cell Therapy Molecular Therapy vol.\n4 original article© The American Society of Gene & Cell Therapy Molecular Therapy vol.\n5 original article© The American Society of Gene & Cell Therapy Molecular Therapy vol.\n6 original article© The American Society of Gene & Cell Therapy Molecular Therapy vol.\n  token_id    token    lemma  upos xpos                     feats\n1        1 original original   ADJ   JJ                Degree=Pos\n2        2 article© article©  NOUN   NN               Number=Sing\n3        3      The      the   DET   DT Definite=Def|PronType=Art\n4        4 American American PROPN  NNP               Number=Sing\n5        5  Society  Society PROPN  NNP               Number=Sing\n6        6       of       of   ADP   IN                      <NA>\n  head_token_id  dep_rel deps misc\n1             2     amod <NA> <NA>\n2            13 compound <NA> <NA>\n3             5      det <NA> <NA>\n4             5     amod <NA> <NA>\n5            13 compound <NA> <NA>\n6             7     case <NA> <NA>\n\nThe other informations we use, and the reason why we work directly on a pdf instead of a text, is the fonts information from the pdf, the font and the fontsize of the words inside the pdf. To do this we use poppler, a PDF rendering library and the cpp API of poppler. We extract this informations using a specific version of pdftools, reason why the package need a version of poppler > 0.89 as well as a recent version of pdftools.\n\n\npoppler_output <- segmenteR::prepare_poppler_output(pdf_name)\nhead(poppler_output)\n\n\n      Word             Font Size\n1        © AOJZVN+StoneSans  6.5\n2      The AOJZVN+StoneSans  6.5\n3 American AOJZVN+StoneSans  6.5\n4  Society AOJZVN+StoneSans  6.5\n5       of AOJZVN+StoneSans  6.5\n6     Gene AOJZVN+StoneSans  6.5\n\nThis informations is used to identify the probable font of the section, by first looking at the font used for the words Reference and Acknowledgment, that usually appear in only one occurrence in scientific articles :\n\n\nfont_section <- segmenteR::identify_font(poppler_output)\nprint(font_section)\n\n\n[1] \"VMUQDX+ITCStoneSans-Semibold\"\n\nKnowing this, we can know which sections are inside the articles and in which order they appear. The list under is the sections titles that the function will try to identify in the poppler output :\n\n\nlist_of_sections <- list(\n    c(\"Introduction\", \"INTRODUCTION\"),\n    c(\"Materials\", \"Material\", \"materials\", \"material\", \"MATERIALS\", \"MATERIAL\"),\n    c(\"Methods\", \"Method\", \"methods\", \"method\", \"METHODS\", \"METHOD\"),\n    c(\"Acknowledgements\", \"Acknowledgments\", \"ACKNOWLEDGEMENTS\", \"ACKNOWLEDGMENTS\",\n      \"Acknowledgement\", \"Acknowledgment\", \"ACKNOWLEDGEMENT\", \"ACKNOWLEDGMENT\"),\n    c(\"References\", \"REFERENCES\"),\n    c(\"Results\", \"RESULTS\"),\n    c(\"Discussion\", \"DISCUSSION\", \"discussion\"),\n    c(\"Abstract\", \"ABSTRACT\"),\n    c(\"Conclusions\", \"Conclusion\", \"CONCLUSION\", \"CONCLUSIONS\"),\n    c(\"Background\", \"BACKGROUND\"),\n    c(\"Experimental\", \"EXPERIMENTAL\", \"Experiment\"),\n    c(\"Supplementary\", \"SUPPLEMENTARY\"),\n    c(\"Methodology\"),\n    c(\"Appendix\"),\n    c(\"Section\", \"SECTION\")\n  )\n\n\n\nClean_font_txt() remove the most common font inside the articles, which improve the correct localization of the sections by create_section_title_df() inside the pdf.\n\n\npoppler_output <- segmenteR::clean_font_txt(poppler_output)\nhead(poppler_output)\n\n\n      Word             Font Size\n1        © AOJZVN+StoneSans  6.5\n2      The AOJZVN+StoneSans  6.5\n3 American AOJZVN+StoneSans  6.5\n4  Society AOJZVN+StoneSans  6.5\n5       of AOJZVN+StoneSans  6.5\n6     Gene AOJZVN+StoneSans  6.5\n\nSection_title_df is a dataframe that contain the section titles in the article and their relative order, based on the fonts information retrieved from the pdf. This informations (order and existence) will be used to localize the section in the ConLL-U format. This step is needed as the order and the composition of the sections title can change from one article to the other.\n\n\nsection_title_df <- segmenteR::create_section_title_df(font_section, list_of_sections, poppler_output)\nsection_title_df <- segmenteR::clean_title_journal(pdf_name, section_title_df)\nsection_title_df <- segmenteR::ad_hoc_reorder(section_title_df)\nhead(section_title_df)\n\n\n                Word                         Font Size\n293     Introduction VMUQDX+ITCStoneSans-Semibold 10.0\n1321         Results VMUQDX+ITCStoneSans-Semibold 10.0\n5243      Discussion VMUQDX+ITCStoneSans-Semibold 10.0\n6214       Materials VMUQDX+ITCStoneSans-Semibold 10.0\n6216         Methods VMUQDX+ITCStoneSans-Semibold 10.0\n7188 Acknowledgments VMUQDX+ITCStoneSans-Semibold  9.2\n\nRemoving the bibliography prevent some error in the localization in some sections, especially if a reference start with the word “material”. This option can be set to false.\n\n\nif (remove_bibliography == TRUE) {\n  conllu_df <- segmenteR::remove_bibliography_from_conllu(conllu_df, section_title_df)\n  section_title_df <- segmenteR::remove_reference_section_from_titles(section_title_df)\n}\n\n\n\nKnowing the relative order of the sections from one side, their names and the informations from the Conll-U dataframe (position inside the sentence, or the other words in the sentence) we can estimate the position of the different sections inside the Conll-U dataframe. Please note that the positions_sections_df is not the section_title_df, since section_title_df refer to the position inside the output from poppler, while section_title_df indicate the position inside the Conll-U dataframe.\n\n\npositions_sections_df <- segmenteR::locate_sections_position_in_conllu(conllu_df, section_title_df)\nsegmenteR::check_sections_df(positions_sections_df)\nhead(positions_sections_df)\n\n\n                section occurrences\n1          Introduction         239\n2               Results        1173\n3            Discussion        6295\n4 Materials and Methods        7563\n6       Acknowledgments        8769\n\n\n\nsection <- segmenteR::extract_section_from_conllu(conllu_df, positions_sections_df, section_aliases)\nhead(unique(section$sentence))\n\n\n[1] \"MAterIAls And Methods Animals.\"                                                                                                                                                                           \n[2] \"Female Crl:CD-1/ICR mice were obtained from Charles River (Wilmington, MA) and were between 6 and 10 weeks old at time of study (25–30 g).\"                                                               \n[3] \"All studies were performed in Merck Research Laboratories′\"                                                                                                                                               \n[4] \"AAALAC-accredited West Point, PA animal facility using protocols approved by the Institutional Animal Care and Use Committee.\"                                                                            \n[5] \"Liposome assemblies, siRNAs, and reagents.\"                                                                                                                                                               \n[6] \"siRNA Lipid Nanoparticles were assembled using a process involving simultaneous mixing of the lipid mixture in an ethanol solution with an aqueous solution of siRNA, followed by stepwise diafiltration.\"\n\nFinally extract_section_from_conllu() provide the section in ConLL-U format inside the dataframe section.\nKnown Gotchas\nDon’t use it on an article of two pages. Ever.\nGithub repository\nMore seriously, the extraction will fail on article of one or two pages, because of a function that remove sections names that have the same number of occurences than the numbers of pages, since some journals have names including “Materials”, or “Results”, wrote in the exact same fonts that the one of the sections titles. It would be something to improve in the definitive version of the package.\nIf you try this package for your project, by curiosity and have some comments or question, or if it does not work on your favorite article, feel free to open an issue on the github repository of the projet, I would be glad to take a look it.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-11T10:12:06+02:00",
    "input_file": "segmenteR.knit.md"
  },
  {
    "path": "posts/Knowledge_distillation_post/",
    "title": "Knowledge distillation with R and tensorflow",
    "description": "A quick tutorial on how to perform Knowledge distillation with R, in eager mode.",
    "author": [
      {
        "name": "Etienne Rolland",
        "url": "https://github.com/Cdk29"
      }
    ],
    "date": "2021-06-04",
    "categories": [],
    "contents": "\n\n\nknitr::opts_chunk$set(echo = TRUE)\n\n\n\nWelcome\nHi everyone ! Welcome to my blog. Here I will just share some tutorials around things that were complicated for me, and for which others R users could be interested. Not surprisingly, lot of this tutorials will involve tensorflow or other deep learning things.\nSometimes things are possible in R, but, since our community is smaller, we don’t have that many resources or tutorials compared to the python community, explaining why it is cubersome to do some particuliar tasks in R, especially when the few tutorials available or interfaces packages start accumulate errors or bugs because they are not used often by an active community.\nI am not an expert, so I will try to source at maximum of my codes, or parameters when I can. I used a small size for the images to not blow my GPU, there is an example with fine tuning and a bigger GPU here.\nThere is probably a lack of optimization, but at least it is a working skeleton. If you have suggestion for improvement, comments are welcome :D\nAbout the data\nI wrote this code in the first place in the context of the Cassava Leaf Disease Classification, a Kaggle’s competition where the goal was to train a model to identify the disease on leafs of cassava. Here the distillation is made from an Efficientnet0 to an other one.\nWhat is knowledge distillation\nAs presented in this discussion thread on kaggle, knowledge distillation is defined as simply trains another individual model to match the output of an ensemble. Source. It is in fact slightly more complicated : the second neural net (student) will made predictions on the images, but then, the losses will be a function of its own loss as well as a loss based on the difference between his prediction and the one of its teacher or the ensemble.\nThis approach allow to compress an ensemble into one model and by then reduce the inference time, or, if trained to match the output of a model, to increase the overall performance of the model. I discover this approach by looking at the top solutions of the Plant Pathology 2020 competition, an other solution with computer vision and leaf, such as this one.\nI let you go to to this source mentioned aboved to understand how it could potentially works. It does not seems sure, but it seems related to the learning of specific features vs forcing the student to learn “multiple view”, multiple type of feature to detect in the images.\nThere is off course, no starting material to do it in R. Thanksfully there is a code example on the website of keras. In this example, they create a class of model, a distiller, to make the knowledge distillation. There is, however, one problem : model are not inheritable in R. There is example of inheritance with a R6 for callback, like here, but the models are not a R6 class. To overcome this problem, I used the code example as a guide, and reproduced the steps by following the approach in this guide for eager executation in keras with R. I took other code from the tensorflow website for R.\nThe code is quite hard to understand at first glance. The reason is, everything is executed in a single for loop, since everything is done in eager mode. It did not seemed possible to do it differently. So there is a lot of variable around to collect metrics during training. If you want to understand the code just remove it from the loop and run it outside of the for loop, before reconstructing the loop around. I did not used tfdataset as shown on the guide for eager execution, so instead of make_iterator_one_shot() and iterator_get_next(), here we loop over the train_generator to produce the batches.\n\n\nlibrary(tidyverse)\nlibrary(tensorflow)\ntf$executing_eagerly()\n\n\n[1] TRUE\n\n\n\ntensorflow::tf_version()\n\n\n[1] '2.3'\n\nHere I flex with my own version of keras. Basically, it is a fork with application wrapper for the efficient net.\nDisclaimer : I did not write the code for the really handy applications wrappers. It came from this commit for which the PR is hold until the fully release of tf 2.3, as stated in this PR. I am not sure why the PR is closed.\n\n\ndevtools::install_github(\"Cdk29/keras\", dependencies = FALSE)\n\n\n\n\n\nlibrary(keras)\n\n\n\n\n\nlabels<-read_csv('train.csv')\nhead(labels)\n\n\n# A tibble: 6 x 2\n  image_id       label\n  <chr>          <dbl>\n1 1000015157.jpg     0\n2 1000201771.jpg     3\n3 100042118.jpg      1\n4 1000723321.jpg     1\n5 1000812911.jpg     3\n6 1000837476.jpg     3\n\n\n\nlevels(as.factor(labels$label))\n\n\n[1] \"0\" \"1\" \"2\" \"3\" \"4\"\n\n\n\nidx0<-which(labels$label==0)\nidx1<-which(labels$label==1)\nidx2<-which(labels$label==2)\nidx3<-which(labels$label==3)\nidx4<-which(labels$label==4)\n\n\n\n\n\nlabels$CBB<-0\nlabels$CBSD<-0\nlabels$CGM<-0\nlabels$CMD<-0\nlabels$Healthy<-0\n\n\n\n\n\nlabels$CBB[idx0]<-1\nlabels$CBSD[idx1]<-1\nlabels$CGM[idx2]<-1\nlabels$CMD[idx3]<-1\n\n\n\n“Would it have been easier to create a function to convert the labelling ?” You may ask.\n\n\nlabels$Healthy[idx4]<-1\n\n\n\nProbably.\n\n\n#labels$label<-NULL\n\n\n\n\n\nhead(labels)\n\n\n# A tibble: 6 x 7\n  image_id       label   CBB  CBSD   CGM   CMD Healthy\n  <chr>          <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>\n1 1000015157.jpg     0     1     0     0     0       0\n2 1000201771.jpg     3     0     0     0     1       0\n3 100042118.jpg      1     0     1     0     0       0\n4 1000723321.jpg     1     0     1     0     0       0\n5 1000812911.jpg     3     0     0     0     1       0\n6 1000837476.jpg     3     0     0     0     1       0\n\n\n\nval_labels<-read_csv('validation_set.csv')\n\n\n\n\n\ntrain_labels<-labels[which(!labels$image_id %in% val_labels$image_id),]\n\n\n\n\n\ntable(train_labels$image_id %in% val_labels$image_id)\n\n\n\nFALSE \n19256 \n\n\n\ntrain_labels$label<-NULL\nval_labels$label<-NULL\n\nhead(train_labels)\n\n\n# A tibble: 6 x 6\n  image_id         CBB  CBSD   CGM   CMD Healthy\n  <chr>          <dbl> <dbl> <dbl> <dbl>   <dbl>\n1 1000015157.jpg     1     0     0     0       0\n2 1000201771.jpg     0     0     0     1       0\n3 100042118.jpg      0     1     0     0       0\n4 1000723321.jpg     0     1     0     0       0\n5 1000812911.jpg     0     0     0     1       0\n6 1000837476.jpg     0     0     0     1       0\n\nhead(val_labels)\n\n\n# A tibble: 6 x 6\n  image_id         CBB  CBSD   CGM   CMD Healthy\n  <chr>          <dbl> <dbl> <dbl> <dbl>   <dbl>\n1 1003442061.jpg     0     0     0     0       1\n2 1004672608.jpg     0     0     0     1       0\n3 1007891044.jpg     0     0     0     1       0\n4 1009845426.jpg     0     0     0     1       0\n5 1010648150.jpg     0     0     0     1       0\n6 1011139244.jpg     0     0     0     1       0\n\n\n\nimage_path<-'cassava-leaf-disease-classification/train_images/'\n\n\n\n\n\n#data augmentation\ndatagen <- image_data_generator(\n  rotation_range = 40,\n  width_shift_range = 0.2,\n  height_shift_range = 0.2,\n  shear_range = 0.2,\n  zoom_range = 0.5,\n  horizontal_flip = TRUE,\n  fill_mode = \"reflect\"\n)\n\n\n\n\n\nimg_path<-\"cassava-leaf-disease-classification/train_images/1000015157.jpg\"\n\nimg <- image_load(img_path, target_size = c(448, 448))\nimg_array <- image_to_array(img)\nimg_array <- array_reshape(img_array, c(1, 448, 448, 3))\nimg_array<-img_array/255\n# Generated that will flow augmented images\naugmentation_generator <- flow_images_from_data(\n  img_array, \n  generator = datagen, \n  batch_size = 1 \n)\nop <- par(mfrow = c(2, 2), pty = \"s\", mar = c(1, 0, 1, 0))\nfor (i in 1:4) {\n  batch <- generator_next(augmentation_generator)\n  plot(as.raster(batch[1,,,]))\n}\n\n\n\npar(op)\n\n\n\nData generator\nOkay so here is an interresting thing, I will try to compress the code to call a train generator to make it easier to call it.\nWhy ? Well, apparently a generator does not yield infinite batches, and the for loop of the distiller will stop working without obvious reason at epoch 7, when reaching the end of the validation generator.\nWhen we iterate over it, validation_generator yeld 8 images and 8 label, until the batch 267, than contains only 5 images (and create the bug when we try to add the loss of the batch to the loss of the epoch. Batch 268 does not exist. So solution seems to recreate on the fly the validation set and restart the iterations.\n\n\narg.list <- list(dataframe = val_labels, directory = image_path,\n                                              class_mode = \"other\",\n                                              x_col = \"image_id\",\n                                              y_col = c(\"CBB\",\"CBSD\", \"CGM\", \"CMD\", \"Healthy\"),\n                                              target_size = c(228, 228),\n                                              batch_size=8)\n\n\n\n\n\nvalidation_generator <- do.call(flow_images_from_dataframe, arg.list)\n\n\n\n\n\ndim(validation_generator[266][[1]])\n\n\n[1]   8 228 228   3\n\n\n\ndim(validation_generator[267][[1]])\n\n\n[1]   5 228 228   3\n\n\n\ndim(val_labels)\n\n\n[1] 2141    6\n\n\n\n2141/8\n\n\n[1] 267.625\n\n\n\ntrain_generator <- flow_images_from_dataframe(dataframe = train_labels, \n                                              directory = image_path,\n                                              generator = datagen,\n                                              class_mode = \"other\",\n                                              x_col = \"image_id\",\n                                              y_col = c(\"CBB\",\"CBSD\", \"CGM\", \"CMD\", \"Healthy\"),\n                                              target_size = c(228, 228),\n                                              batch_size=8)\n\nvalidation_generator <- flow_images_from_dataframe(dataframe = val_labels, \n                                              directory = image_path,\n                                              class_mode = \"other\",\n                                              x_col = \"image_id\",\n                                              y_col = c(\"CBB\",\"CBSD\", \"CGM\", \"CMD\", \"Healthy\"),\n                                              target_size = c(228, 228),\n                                              batch_size=8)\n\n\n\n\n\ntrain_generator\n\n\n<tensorflow.python.keras.preprocessing.image.DataFrameIterator>\n\n\n\nconv_base<-keras::application_efficientnet_b0(weights = \"imagenet\", include_top = FALSE, input_shape = c(228, 228, 3))\n\nfreeze_weights(conv_base)\n\nmodel <- keras_model_sequential() %>%\n    conv_base %>% \n    layer_global_max_pooling_2d() %>% \n    layer_batch_normalization() %>% \n    layer_dropout(rate=0.5) %>%\n    layer_dense(units=5, activation=\"softmax\")\n\n\n\n\n\n#unfreeze_weights(model, from = 'block5a_expand_conv')\nunfreeze_weights(conv_base, from = 'block5a_expand_conv')\n\n\n\n\n\nmodel %>% load_model_weights_hdf5(\"fine_tuned_eff_net_weights.15.hdf5\")\n\n\n\n\n\nsummary(model)\n\n\nModel: \"sequential\"\n______________________________________________________________________\nLayer (type)                   Output Shape                Param #    \n======================================================================\nefficientnetb0 (Functional)    (None, 8, 8, 1280)          4049571    \n______________________________________________________________________\nglobal_max_pooling2d (GlobalMa (None, 1280)                0          \n______________________________________________________________________\nbatch_normalization (BatchNorm (None, 1280)                5120       \n______________________________________________________________________\ndropout (Dropout)              (None, 1280)                0          \n______________________________________________________________________\ndense (Dense)                  (None, 5)                   6405       \n======================================================================\nTotal params: 4,061,096\nTrainable params: 3,707,853\nNon-trainable params: 353,243\n______________________________________________________________________\n\n\n\nconv_base_student<-keras::application_efficientnet_b0(weights = \"imagenet\", include_top = FALSE, input_shape = c(228, 228, 3))\n\nfreeze_weights(conv_base_student)\n\nstudent <- keras_model_sequential() %>%\n    conv_base_student %>% \n    layer_global_max_pooling_2d() %>% \n    layer_batch_normalization() %>% \n    layer_dropout(rate=0.5) %>%\n    layer_dense(units=5, activation=\"softmax\")\n\nstudent\n\n\nModel\nModel: \"sequential_1\"\n______________________________________________________________________\nLayer (type)                   Output Shape                Param #    \n======================================================================\nefficientnetb0 (Functional)    (None, 8, 8, 1280)          4049571    \n______________________________________________________________________\nglobal_max_pooling2d_1 (Global (None, 1280)                0          \n______________________________________________________________________\nbatch_normalization_1 (BatchNo (None, 1280)                5120       \n______________________________________________________________________\ndropout_1 (Dropout)            (None, 1280)                0          \n______________________________________________________________________\ndense_1 (Dense)                (None, 5)                   6405       \n======================================================================\nTotal params: 4,061,096\nTrainable params: 8,965\nNon-trainable params: 4,052,131\n______________________________________________________________________\n\nSource code and knowledge distillation\nSource code for knowledge distillation with Keras : https://keras.io/examples/vision/knowledge_distillation/\nHelp for eager executation details in R and various usefull code : https://keras.rstudio.com/articles/eager_guide.html\nOther source code in R : https://tensorflow.rstudio.com/tutorials/advanced/\nI am using an alpha parameter of 0.9 as suggested by this article.\n\n\ni=1\nalpha=0.9 #On_the_Efficacy_of_Knowledge_Distillation_ICCV_2019\ntemperature=3\n\n\n\n\n\noptimizer <- optimizer_adam()\n\n\n\n\n\ntrain_loss <- tf$keras$metrics$Mean(name='student_loss')\ntrain_accuracy <-  tf$keras$metrics$CategoricalAccuracy(name='train_accuracy')\n\n\n\n\n\nnb_epoch<-12\n\n\n\n\n\nnb_batch<-300\nval_step<-40\n\n\n\n\n\ntrain_loss_plot<-c()\naccuracy_plot<-c()\ndistilation_loss_plot <- c()\n\n\n\n\n\nval_loss_plot <- c()\nval_accuracy_plot <- c()\n\n\n\n\n\ncount_epoch<-0\n\n\n\n\n\nfor (epoch in 1:nb_epoch) {\n    cat(\"Epoch: \", epoch, \" -----------\\n\")\n    # Init metrics\n    train_loss_epoch <- 0\n    accuracies_on_epoch <- c()\n    distilation_loss_epoch <- 0\n    val_loss_epoch <- 0\n    val_accuaries_on_epoch <- c()\n    \n    #Formula to not see the same batch over and over on each epoch\n    #Count epoch instead of epoch\n    count_epoch<-count_epoch+1\n    idx_batch <- (1+nb_batch*(count_epoch-1)):(nb_batch*count_epoch)\n    idx_val_set <- (1+val_step*(count_epoch-1)):(val_step*count_epoch)\n    \n    #Dirty solution to restart on a new validation batch generator before reaching the end of the other one \n    if (as.integer((dim(val_labels)[1]/8)-1) %in% idx_val_set) {\n        count_epoch<-1\n        idx_val_set <- (1+val_step*(count_epoch-1)):(val_step*count_epoch)\n        validation_generator <- do.call(flow_images_from_dataframe, arg.list)\n    }\n    #need the same if for train generator\n    if (as.integer((dim(train_labels)[1]/8)-1) %in% idx_batch) {\n        count_epoch<-1\n        idx_batch <- (1+nb_batch*(count_epoch-1)):(nb_batch*count_epoch)\n        train_generator <- do.call(flow_images_from_dataframe, arg.list)\n    }\n    \n    for (batch in idx_batch) {\n        x = train_generator[batch][[1]]\n        y = train_generator[batch][[2]]\n        # Forward pass of teacher\n        teacher_predictions = model(x)\n\n        with(tf$GradientTape() %as% tape, {\n            student_predictions = student(x)\n            student_loss = tf$losses$categorical_crossentropy(y, student_predictions)\n        \n            distillation_loss = tf$losses$categorical_crossentropy(tf$nn$softmax(teacher_predictions/temperature, axis=0L), \n                                                           tf$nn$softmax(student_predictions/temperature, axis=0L))\n        \n            loss = alpha * student_loss + (1 - alpha) * distillation_loss\n            })\n        \n        # Compute gradients\n        # Variating learning rate :\n        # optimizer <- optimizer_adam(lr = 0.0001)\n        gradients <- tape$gradient(loss, student$trainable_variables)\n        optimizer$apply_gradients(purrr::transpose(list(gradients, student$trainable_variables)))\n        \n        #Collect the metrics of the student\n        train_loss_epoch <- train_loss_epoch + student_loss\n        distilation_loss_epoch <- distilation_loss_epoch + distillation_loss\n        \n        accuracy_on_batch <- train_accuracy(y_true=y, y_pred=student_predictions)\n        accuracies_on_epoch <- c(accuracies_on_epoch, as.numeric(accuracy_on_batch))\n        \n    }\n\n    #Collect info on current epoch and for graphs and cat()\n    train_loss_epoch <- mean(as.vector(as.numeric(train_loss_epoch))/nb_batch)\n    train_loss_plot <- c(train_loss_plot, train_loss_epoch)\n    \n    distilation_loss_epoch <- mean(as.vector(as.numeric(distilation_loss_epoch))/nb_batch)\n    distilation_loss_plot <- c(distilation_loss_plot, distilation_loss_epoch)\n    \n    accuracies_on_epoch <- mean(accuracies_on_epoch)\n    accuracy_plot <- c(accuracy_plot, accuracies_on_epoch)\n    \n    \n    for (step in idx_val_set) {\n        # Unpack the data\n        x = validation_generator[step][[1]]\n        y = validation_generator[step][[2]]\n\n        # Compute predictions\n        student_predictions = student(x)\n\n        # Calculate the loss\n        student_loss = tf$losses$categorical_crossentropy(y, student_predictions)\n\n        #Collect the metrics of the student\n        #This line will create a bug of shape when val_loss end.\n        val_loss_epoch <- val_loss_epoch + student_loss\n        \n        accuracy_on_val_step <- train_accuracy(y_true=y, y_pred=student_predictions)\n        val_accuaries_on_epoch <- c(val_accuaries_on_epoch, as.numeric(accuracy_on_val_step))\n    }\n    \n    #Collect info on current epoch and for graphs and cat()\n    val_loss_epoch <- mean(as.vector(as.numeric(val_loss_epoch))/val_step)\n    val_loss_plot <- c(val_loss_plot, val_loss_epoch)\n    \n    val_accuaries_on_epoch <- mean(val_accuaries_on_epoch)\n    val_accuracy_plot <- c(val_accuracy_plot, val_accuaries_on_epoch)\n    \n    #Plotting\n    cat(\"Total loss (epoch): \", epoch, \": \", train_loss_epoch, \"\\n\")\n    cat(\"Distillater loss : \", epoch, \": \", distilation_loss_epoch, \"\\n\")\n    cat(\"Accuracy (epoch): \", epoch, \": \", accuracies_on_epoch, \"\\n\")\n    cat(\"Val loss : \", epoch, \": \", val_loss_epoch, \"\\n\")\n    cat(\"Val Accuracy (epoch): \", epoch, \": \", val_accuaries_on_epoch, \"\\n\")\n}\n\n\nEpoch:  1  -----------\nTotal loss (epoch):  1 :  1.970847 \nDistillater loss :  1 :  1.006515 \nAccuracy (epoch):  1 :  0.5028956 \nVal loss :  1 :  1.683065 \nVal Accuracy (epoch):  1 :  0.5337647 \nEpoch:  2  -----------\nTotal loss (epoch):  2 :  1.671758 \nDistillater loss :  2 :  1.006187 \nAccuracy (epoch):  2 :  0.5482197 \nVal loss :  2 :  1.746699 \nVal Accuracy (epoch):  2 :  0.5590533 \nEpoch:  3  -----------\nTotal loss (epoch):  3 :  1.618646 \nDistillater loss :  3 :  1.006112 \nAccuracy (epoch):  3 :  0.5649438 \nVal loss :  3 :  1.531488 \nVal Accuracy (epoch):  3 :  0.5679042 \nEpoch:  4  -----------\nTotal loss (epoch):  4 :  1.562328 \nDistillater loss :  4 :  1.005987 \nAccuracy (epoch):  4 :  0.575272 \nVal loss :  4 :  1.508584 \nVal Accuracy (epoch):  4 :  0.5776999 \nEpoch:  5  -----------\nTotal loss (epoch):  5 :  1.406053 \nDistillater loss :  5 :  1.005917 \nAccuracy (epoch):  5 :  0.5815135 \nVal loss :  5 :  1.372146 \nVal Accuracy (epoch):  5 :  0.5892469 \nEpoch:  6  -----------\nTotal loss (epoch):  6 :  1.520737 \nDistillater loss :  6 :  1.005878 \nAccuracy (epoch):  6 :  0.5893831 \nVal loss :  6 :  1.34237 \nVal Accuracy (epoch):  6 :  0.5902871 \nEpoch:  7  -----------\nTotal loss (epoch):  7 :  1.508101 \nDistillater loss :  7 :  1.005872 \nAccuracy (epoch):  7 :  0.5920453 \nVal loss :  7 :  2.097656 \nVal Accuracy (epoch):  7 :  0.5925921 \nEpoch:  8  -----------\nTotal loss (epoch):  8 :  1.267969 \nDistillater loss :  8 :  1.005815 \nAccuracy (epoch):  8 :  0.5949023 \nVal loss :  8 :  1.78513 \nVal Accuracy (epoch):  8 :  0.5982342 \nEpoch:  9  -----------\nTotal loss (epoch):  9 :  1.510699 \nDistillater loss :  9 :  1.005925 \nAccuracy (epoch):  9 :  0.5991197 \nVal loss :  9 :  1.387395 \nVal Accuracy (epoch):  9 :  0.5990839 \nEpoch:  10  -----------\nTotal loss (epoch):  10 :  1.495111 \nDistillater loss :  10 :  1.005821 \nAccuracy (epoch):  10 :  0.6014644 \nVal loss :  10 :  2.015202 \nVal Accuracy (epoch):  10 :  0.6017212 \nEpoch:  11  -----------\nTotal loss (epoch):  11 :  1.454717 \nDistillater loss :  11 :  1.00589 \nAccuracy (epoch):  11 :  0.6021615 \nVal loss :  11 :  1.659231 \nVal Accuracy (epoch):  11 :  0.6034705 \nEpoch:  12  -----------\nTotal loss (epoch):  12 :  1.37668 \nDistillater loss :  12 :  1.005826 \nAccuracy (epoch):  12 :  0.6035553 \nVal loss :  12 :  1.438908 \nVal Accuracy (epoch):  12 :  0.604799 \n\nWhat about global_step = tf.train.get_or_create_global_step() describe here ? It seems to only refers to the number of batches seen by the graph. Source.\nPlotting\n\n\ntotal_loss_plot<-c()\n\n\n\n\n\n#instead of collecting them during the training : \ntotal_loss_plot <- alpha * train_loss_plot + (1 - alpha) * distilation_loss_plot\n\n\n\n\n\ndata <- data.frame(\"Student_loss\" = train_loss_plot, \n                    \"Distillation_loss\" = distilation_loss_plot,\n                   \"Total_loss\" = total_loss_plot,\n                    \"Epoch\" = 1:length(train_loss_plot),\n                    \"Val_loss\" = val_loss_plot,\n                    \"Train_accuracy\"= accuracy_plot,\n                    \"Val_accuracy\"= val_accuracy_plot)\n\n\n\n\n\nhead(data)\n\n\n  Student_loss Distillation_loss Total_loss Epoch Val_loss\n1     1.970847          1.006515   1.874414     1 1.683065\n2     1.671758          1.006187   1.605201     2 1.746699\n3     1.618646          1.006112   1.557393     3 1.531488\n4     1.562328          1.005987   1.506694     4 1.508584\n5     1.406053          1.005917   1.366040     5 1.372146\n6     1.520737          1.005878   1.469251     6 1.342370\n  Train_accuracy Val_accuracy\n1      0.5028956    0.5337647\n2      0.5482197    0.5590533\n3      0.5649438    0.5679042\n4      0.5752720    0.5776999\n5      0.5815135    0.5892469\n6      0.5893831    0.5902871\n\nWhere total_loss is alpha * train_loss_plot * (1 - alpha) * distilation_loss_plot\n\n\nggplot(data, aes(Epoch)) +\n  scale_colour_manual(values=c(Student_loss=\"#F8766D\",Val_loss=\"#00BFC4\", Distillation_loss=\"#DE8C00\", Total_loss=\"#1aff8c\")) +\n  geom_line(aes(y = Student_loss, colour = \"Student_loss\")) + \n  geom_line(aes(y = Val_loss, colour = \"Val_loss\")) + \n  geom_line(aes(y = Total_loss, colour = \"Total_loss\")) + \n  geom_line(aes(y = Distillation_loss, colour = \"Distillation_loss\"))\n\n\n\n#Validation set\nggplot(data, aes(Epoch)) + \n  geom_line(aes(y = Train_accuracy, colour = \"Train_accuracy\")) + \n  geom_line(aes(y = Val_accuracy, colour = \"Val_accuracy\"))\n\n\n\n\nFine tuning and conclusion\nIs that all ? Well, no. Here we perform knowledge distillation to teach to the head of the student network.\nThe next step would be to reproduce the knowledge distillation after unfreezing some part of the student, after writing something like :\n\n\nunfreeze_weights(conv_base_student, from = 'block5a_expand_conv')\n\n\n\nBut I will not bet my small GPU card on this or start a fire in my basement for the sake of the tutorial.\nAs I mentioned earlier, I readapted my code from kaggle, where the gpu is much bigger. Take a look if you want to see, but basically the end output looks like this :\nlossaccuracyWell, that’s it for this post, which is probably already lengthy enough for a blog post !\n\n\n\n",
    "preview": "posts/Knowledge_distillation_post/distill-preview.png",
    "last_modified": "2021-06-04T20:16:53+02:00",
    "input_file": "Knowledge-distillation-with-R-and-Keras.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  }
]
