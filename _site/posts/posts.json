[
  {
    "path": "posts/welcome/",
    "title": "segmenteR, a small tool to segment a scientific article",
    "description": "Welcome to my new blog, casualR. I hope you will find some useful content !",
    "author": [
      {
        "name": "Etienne Rolland",
        "url": "https://github.com/Cdk29"
      }
    ],
    "date": "2021-05-31",
    "categories": [],
    "contents": "\nsegmenteR\nHi everyone ! Whether it is to perform systematic review, some data extraction, or a really specific project that requires it, you may need to extract a particular section from an scientific article in pdf format. If that is the case, you may be curious in this (prototype) R package, segmenteR, a tool to extract a section, for example, “material and methods”, from the pdf of an article, using the fonts information from the pdf and natural language processing.\nContext\nIt has been elaborated in the context of a research work conducted at the Joint Research Centre, Directorate F - Health, Consumers and Reference Materials, Ispra (VA), as a sub-part of a project that aimed to analyse a corpus of 801 articles, obtained from the PubMed MeSH database and related to several toxicity topics (cardiotoxicity, genotoxicity, etc).\nWe needed to extract both the material and methods section and the results section of each articles, to evaluate the quality of the reporting inside each articles and parse the texts for specific toxicity effects. The work has been published in the Journal of Applied Toxicology, Toxicity effects of nanomaterials for health applications: how automation can support systematic review of the literature ? Blanka Halamoda-Kenzaoui, Etienne Rolland, Jacopo Piovesan, Antonio Puertas Gallardo, Susanne Bremer-Hoffmann doi.org/10.1002/jat.4204.\nWhile this tool is a prototype, it has a small benchmark to evaluate its performances, as shown inside the article.\nRequirement\nTo extract the informations on the fonts inside the pdf we use Poppler, the PDF rendering library and its cpp API. SegmenteR require a version of poppler >= 0.89 as well as a recent version of pdftools. The dev version of pdftools integrate the required change, but you need to install it from github :\n\n\ndevtools::install_github(\"ropensci/pdftools\") \ndevtools::install_github(\"ec-jrc/jrc_f2_refine\", subdir=\"segmenteR\") \n\n\n\nGetting started\nThe short way\nDownload an open access article that was part of the corpus :\n\n\nurl <- ('https://www.cell.com/action/showPdf?pii=S1525-0016%2816%2931594-5')\ndownload.file(url, 'Abrams, M T et al 2010.pdf')\n\n\n\nWe need a model and from the library udpipe to tokenize and annotate the text :\n\n\n## got the model for annotation\ndl <- udpipe::udpipe_download_model(\"english-gum\")\nstr(dl)\n\n\n'data.frame':   1 obs. of  5 variables:\n $ language        : chr \"english-gum\"\n $ file_model      : chr \"/home/erolland/Bureau/casualR/_posts/welcome/english-gum-ud-2.5-191206.udpipe\"\n $ url             : chr \"https://raw.githubusercontent.com/jwijffels/udpipe.models.ud.2.5/master/inst/udpipe-ud-2.5-191206/english-gum-u\"| __truncated__\n $ download_failed : logi FALSE\n $ download_message: chr \"OK\"\n\n\n\nmodel <- udpipe::udpipe_load_model(file = dl$file_model)\n#model\n\n\n\n\n\nlibrary(segmenteR)\n## basic example code\n\nsection_aliases <- c(\"material\", \"method\", \"experimental\", \"experiment\", \"methodology\")\n\n#model definition can be skipped, the function can download it automatically\nmaterial_and_methods <- segmenteR::extract_section_from_pdf(pdf_name=\"Abrams, M T et al 2010.pdf\",\n                                                             udpipe_model=model, \n                                                             section_aliases=section_aliases)\n\nhead(unique(material_and_methods$sentence))\n\n\n[1] \"MAterIAls And Methods Animals.\"                                                                                                                                                                           \n[2] \"Female Crl:CD-1/ICR mice were obtained from Charles River (Wilmington, MA) and were between 6 and 10 weeks old at time of study (25–30 g).\"                                                               \n[3] \"All studies were performed in Merck Research Laboratories′\"                                                                                                                                               \n[4] \"AAALAC-accredited West Point, PA animal facility using protocols approved by the Institutional Animal Care and Use Committee.\"                                                                            \n[5] \"Liposome assemblies, siRNAs, and reagents.\"                                                                                                                                                               \n[6] \"siRNA Lipid Nanoparticles were assembled using a process involving simultaneous mixing of the lipid mixture in an ethanol solution with an aqueous solution of siRNA, followed by stepwise diafiltration.\"\n\nAnd shazam, you have (hopefully) your material and methods section in ConLL-U format inside the dataframe material_and_methods, a format suitable for parsing, etc. You can stop reading this blog entry here.\nA more in-depth example\nThis example show the inner working of the function extract_section_from_pdf(), and some functions you made need :\n\n\npdf_name <- \"Abrams, M T et al 2010.pdf\"\nremove_bibliography <- TRUE\n\ntxt_pdf <- tabulizer::extract_text(pdf_name) # read the text from the pdf\ntxt_pdf <- segmenteR::preprocess_article_txt(txt_pdf)\n\n\n\nThe role of the function annotate_txt_pdf() is to load the required model and use the library udpipe to tokenize and annotate the text. Please refer to the vignette or the excellent website of udpipe to get more details on the Conll-U format. The reason for this annotation is that we will need it to estimate where the section titles are the most likely placed. For example, if it is the first word of a sentence, if the the word of the sentence is also a section title, etc, it is probably a section title.\n\n\nconllu_df <- segmenteR::annotate_txt_pdf(txt_pdf, udpipe_model=model ) # create the dataframe for NLP using udpipe\nhead(conllu_df)\n\n\n  doc_id paragraph_id sentence_id\n1   doc1            1           1\n2   doc1            1           1\n3   doc1            1           1\n4   doc1            1           1\n5   doc1            1           1\n6   doc1            1           1\n                                                                              sentence\n1 original article© The American Society of Gene & Cell Therapy Molecular Therapy vol.\n2 original article© The American Society of Gene & Cell Therapy Molecular Therapy vol.\n3 original article© The American Society of Gene & Cell Therapy Molecular Therapy vol.\n4 original article© The American Society of Gene & Cell Therapy Molecular Therapy vol.\n5 original article© The American Society of Gene & Cell Therapy Molecular Therapy vol.\n6 original article© The American Society of Gene & Cell Therapy Molecular Therapy vol.\n  token_id    token    lemma  upos xpos                     feats\n1        1 original original   ADJ   JJ                Degree=Pos\n2        2 article© article©  NOUN   NN               Number=Sing\n3        3      The      the   DET   DT Definite=Def|PronType=Art\n4        4 American American PROPN  NNP               Number=Sing\n5        5  Society  Society PROPN  NNP               Number=Sing\n6        6       of       of   ADP   IN                      <NA>\n  head_token_id  dep_rel deps misc\n1             2     amod <NA> <NA>\n2            13 compound <NA> <NA>\n3             5      det <NA> <NA>\n4             5     amod <NA> <NA>\n5            13 compound <NA> <NA>\n6             7     case <NA> <NA>\n\nThe other informations we use, and the reason why we work directly on a pdf instead of a text, is the fonts information from the pdf, the font and the fontsize of the words inside the pdf. To do this we use poppler, a PDF rendering library and the cpp API of poppler. We extract this informations using a specific version of pdftools, reason why the package need a version of poppler > 0.89 as well as a recent version of pdftools.\n\n\npoppler_output <- segmenteR::prepare_poppler_output(pdf_name)\nhead(poppler_output)\n\n\n      Word             Font Size\n1        © AOJZVN+StoneSans  6.5\n2      The AOJZVN+StoneSans  6.5\n3 American AOJZVN+StoneSans  6.5\n4  Society AOJZVN+StoneSans  6.5\n5       of AOJZVN+StoneSans  6.5\n6     Gene AOJZVN+StoneSans  6.5\n\nThis informations is used to identify the probable font of the section, by first looking at the font used for the words Reference and Acknowledgment, that usually appear in only one occurrence in scientific articles :\n\n\nfont_section <- segmenteR::identify_font(poppler_output)\nprint(font_section)\n\n\n[1] \"VMUQDX+ITCStoneSans-Semibold\"\n\nKnowing this, we can know which sections are inside the articles and in which order they appear. The list under is the sections titles that the function will try to identify in the poppler output :\n\n\nlist_of_sections <- list(\n    c(\"Introduction\", \"INTRODUCTION\"),\n    c(\"Materials\", \"Material\", \"materials\", \"material\", \"MATERIALS\", \"MATERIAL\"),\n    c(\"Methods\", \"Method\", \"methods\", \"method\", \"METHODS\", \"METHOD\"),\n    c(\"Acknowledgements\", \"Acknowledgments\", \"ACKNOWLEDGEMENTS\", \"ACKNOWLEDGMENTS\",\n      \"Acknowledgement\", \"Acknowledgment\", \"ACKNOWLEDGEMENT\", \"ACKNOWLEDGMENT\"),\n    c(\"References\", \"REFERENCES\"),\n    c(\"Results\", \"RESULTS\"),\n    c(\"Discussion\", \"DISCUSSION\", \"discussion\"),\n    c(\"Abstract\", \"ABSTRACT\"),\n    c(\"Conclusions\", \"Conclusion\", \"CONCLUSION\", \"CONCLUSIONS\"),\n    c(\"Background\", \"BACKGROUND\"),\n    c(\"Experimental\", \"EXPERIMENTAL\", \"Experiment\"),\n    c(\"Supplementary\", \"SUPPLEMENTARY\"),\n    c(\"Methodology\"),\n    c(\"Appendix\"),\n    c(\"Section\", \"SECTION\")\n  )\n\n\n\nClean_font_txt() remove the most common font inside the articles, which improve the correct localization of the sections by create_section_title_df() inside the pdf.\n\n\npoppler_output <- segmenteR::clean_font_txt(poppler_output)\nhead(poppler_output)\n\n\n      Word             Font Size\n1        © AOJZVN+StoneSans  6.5\n2      The AOJZVN+StoneSans  6.5\n3 American AOJZVN+StoneSans  6.5\n4  Society AOJZVN+StoneSans  6.5\n5       of AOJZVN+StoneSans  6.5\n6     Gene AOJZVN+StoneSans  6.5\n\nSection_title_df is a dataframe that contain the section titles in the article and their relative order, based on the fonts information retrieved from the pdf. This informations (order and existence) will be used to localize the section in the ConLL-U format. This step is needed as the order and the composition of the sections title can change from one article to the other.\n\n\nsection_title_df <- segmenteR::create_section_title_df(font_section, list_of_sections, poppler_output)\nsection_title_df <- segmenteR::clean_title_journal(pdf_name, section_title_df)\nsection_title_df <- segmenteR::ad_hoc_reorder(section_title_df)\nhead(section_title_df)\n\n\n                Word                         Font Size\n293     Introduction VMUQDX+ITCStoneSans-Semibold 10.0\n1321         Results VMUQDX+ITCStoneSans-Semibold 10.0\n5243      Discussion VMUQDX+ITCStoneSans-Semibold 10.0\n6214       Materials VMUQDX+ITCStoneSans-Semibold 10.0\n6216         Methods VMUQDX+ITCStoneSans-Semibold 10.0\n7188 Acknowledgments VMUQDX+ITCStoneSans-Semibold  9.2\n\nRemoving the bibliography prevent some error in the localization in some sections, especially if a reference start with the word “material”. This option can be set to false.\n\n\nif (remove_bibliography == TRUE) {\n  conllu_df <- segmenteR::remove_bibliography_from_conllu(conllu_df, section_title_df)\n  section_title_df <- segmenteR::remove_reference_section_from_titles(section_title_df)\n}\n\n\n\nKnowing the relative order of the sections from one side, their names and the informations from the Conll-U dataframe (position inside the sentence, or the other words in the sentence) we can estimate the position of the different sections inside the Conll-U dataframe. Please note that the positions_sections_df is not the section_title_df, since section_title_df refer to the position inside the output from poppler, while section_title_df indicate the position inside the Conll-U dataframe.\n\n\npositions_sections_df <- segmenteR::locate_sections_position_in_conllu(conllu_df, section_title_df)\nsegmenteR::check_sections_df(positions_sections_df)\nhead(positions_sections_df)\n\n\n                section occurrences\n1          Introduction         239\n2               Results        1173\n3            Discussion        6295\n4 Materials and Methods        7563\n6       Acknowledgments        8769\n\n\n\nsection <- segmenteR::extract_section_from_conllu(conllu_df, positions_sections_df, section_aliases)\nhead(unique(section$sentence))\n\n\n[1] \"MAterIAls And Methods Animals.\"                                                                                                                                                                           \n[2] \"Female Crl:CD-1/ICR mice were obtained from Charles River (Wilmington, MA) and were between 6 and 10 weeks old at time of study (25–30 g).\"                                                               \n[3] \"All studies were performed in Merck Research Laboratories′\"                                                                                                                                               \n[4] \"AAALAC-accredited West Point, PA animal facility using protocols approved by the Institutional Animal Care and Use Committee.\"                                                                            \n[5] \"Liposome assemblies, siRNAs, and reagents.\"                                                                                                                                                               \n[6] \"siRNA Lipid Nanoparticles were assembled using a process involving simultaneous mixing of the lipid mixture in an ethanol solution with an aqueous solution of siRNA, followed by stepwise diafiltration.\"\n\nFinally extract_section_from_conllu() provide the section in ConLL-U format inside the dataframe section.\nKnown Gotchas\nDon’t use it on an article of two pages. Ever.\nGithub repository\nMore seriously, the extraction will fail on article of one or two pages, because of a function that remove sections names that have the same number of occurences than the numbers of pages, since some journals have names including “Materials”, or “Results”, wrote in the exact same fonts that the one of the sections titles. It would be something to improve in the definitive version of the package.\nIf you try this package for your project, by curiosity and have some comments or question, or if it does not work on your favorite article, feel free to open an issue on the github repository of the projet, I would be glad to take a look it.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-01T08:36:35+02:00",
    "input_file": "welcome.knit.md"
  }
]
